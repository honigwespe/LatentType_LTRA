{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/honigwespe/LatentType_LTRA/blob/main/LatentType_LTRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a95d54b0-a7fa-4193-b4e3-78a84cd9c564",
      "metadata": {
        "tags": [],
        "id": "a95d54b0-a7fa-4193-b4e3-78a84cd9c564"
      },
      "source": [
        "# **Stable Diffusion finetuned on letter \"a\"**\n",
        "\n",
        "This notebook was adapted from the [Stable Diffusion notebook](https://colab.research.google.com/github/deforum/stable-diffusion/blob/main/Deforum_Stable_Diffusion.ipynb) by [deforum](https://discord.gg/upmXXsrwZc).\n",
        "\n",
        "[Stable Diffusion](https://github.com/CompVis/stable-diffusion) by Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Bj√∂rn Ommer and the [Stability.ai](https://stability.ai/) Team, finetuned on letter \"A\" using the [Dreambooth notebook](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast-DreamBooth.ipynb) by [The Last Ben](https://github.com/TheLastBen) and [K Diffusion](https://github.com/crowsonkb/k-diffusion) by [Katherine Crowson](https://twitter.com/RiversHaveWings).\n",
        "\n",
        "The finetuned model checkpoint can be found [here](https://huggingface.co/annafay/ltra/tree/main)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown **Model and Output Paths**\n",
        "# ask for the link\n",
        "print(\"Local Path Variables:\\n\")\n",
        "\n",
        "models_path = \"/content/stablediffusion/models\" #@param {type:\"string\"}\n",
        "output_path = \"/content/stablediffusion/output\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown **Google Drive Path Variables (Optional)**\n",
        "mount_google_drive = True #@param {type:\"boolean\"}\n",
        "force_remount = False\n",
        "\n",
        "if mount_google_drive:\n",
        "    from google.colab import drive # type: ignore\n",
        "    try:\n",
        "        drive_path = \"/content/drive\"\n",
        "        drive.mount(drive_path,force_remount=force_remount)\n",
        "        models_path_gdrive = \"/content/drive/MyDrive/stablediffusion/models\" #@param {type:\"string\"}\n",
        "        output_path_gdrive = \"/content/drive/MyDrive/stablediffusion/output\" #@param {type:\"string\"}\n",
        "        models_path = models_path_gdrive\n",
        "        output_path = output_path_gdrive\n",
        "    except:\n",
        "        print(\"...error mounting drive or with drive path variables\")\n",
        "        print(\"...reverting to default path variables\")\n",
        "\n",
        "import os\n",
        "os.makedirs(models_path, exist_ok=True)\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "print(f\"models_path: {models_path}\")\n",
        "print(f\"output_path: {output_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9GfuL3tSBY0u"
      },
      "id": "9GfuL3tSBY0u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Connect to NVIDIA GPU\n",
        "#@markdown **NVIDIA GPU**\n",
        "import subprocess\n",
        "sub_p_res = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,memory.free', '--format=csv,noheader'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "print(sub_p_res)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xRkhvkZi7gkp"
      },
      "id": "xRkhvkZi7gkp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9be19ca5-5898-461a-9d6a-1125176d71f6",
      "metadata": {
        "tags": [],
        "id": "9be19ca5-5898-461a-9d6a-1125176d71f6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 2. Install & Update Dependencies\n",
        "\n",
        "%%sh\n",
        "pip install -q --upgrade pip\n",
        "pip install -q --upgrade diffusers transformers scipy ftfy huggingface_hub torch\n",
        "pip install accelerate\n",
        "pip install pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76e38afc-87dd-45e5-ac6b-d506e7fdcaa7",
      "metadata": {
        "tags": [],
        "id": "76e38afc-87dd-45e5-ac6b-d506e7fdcaa7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "#@title 3. Login to Huggingface\n",
        "\n",
        "token =\"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\" #@param {type:\"string\"}\n",
        "# Required to get access to stable diffusion model\n",
        "login(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60d68fc2-5569-46db-b0b2-a2b544442b4e",
      "metadata": {
        "tags": [],
        "id": "60d68fc2-5569-46db-b0b2-a2b544442b4e",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 4. Load the Model & Setup the Pipeline\n",
        "%pip install torch\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "model = \"annafay/ltra\"  #@param [\"annafay/ltra\", \"CompVis/stable-diffusion-v1-4\", \"runwayml/stable-diffusion-v1-5\" ] {type:\"raw\"}\n",
        "pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "    model\n",
        ")\n",
        "\n",
        "disable_safety_checker = True #@param {type:\"boolean\"}\n",
        "if disable_safety_checker == True:\n",
        "  safety_checker = pipeline.safety_checker\n",
        "  feature_extractor = pipeline.feature_extractor\n",
        "  pipeline = StableDiffusionPipeline.from_pretrained(model, safety_checker = None)\n",
        "\n",
        "pipeline = pipeline.to(\"cuda\")\n",
        "pipeline.scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcfb7934-7c7d-4732-8e41-941bbbb8d11c",
      "metadata": {
        "tags": [],
        "cellView": "form",
        "id": "fcfb7934-7c7d-4732-8e41-941bbbb8d11c"
      },
      "outputs": [],
      "source": [
        "#@title Optional: Check compatible Samplers and their Configuration\n",
        "pipeline.scheduler.compatibles\n",
        "pipeline.scheduler.config"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b20483d-ecfb-42e4-8349-093c4137d2e6",
      "metadata": {
        "id": "1b20483d-ecfb-42e4-8349-093c4137d2e6"
      },
      "source": [
        "# **5. Generate images**\n",
        "\n",
        "The next cells will generate images for a random selection of seeds for all the prompts listed below. <br>\n",
        "I recommend to use 20 sampling steps, a guidance scale of 3 and the Euler-a sampler. All settings will be saved to the filename."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb86d110-389f-4494-b31a-87c97896f509",
      "metadata": {
        "tags": [],
        "id": "bb86d110-389f-4494-b31a-87c97896f509"
      },
      "outputs": [],
      "source": [
        "#@title Prompts\n",
        "prompts = [\n",
        "    \"LTRA, sans-serif\",\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Settings\n",
        "\n",
        "width = 512 #@param {type:\"string\"}\n",
        "height = 512 #@param {type:\"string\"}\n",
        "number_of_seeds = 10 #@param {type:\"integer\"}\n",
        "sampler = 'euler-a' #@param [\"lms\", \"ddpm\", \"ddim\", \"euler-a\", \"euler\", \"heun\", \"pndm\"]\n",
        "sampling_steps = 20 #@param {type:\"integer\"}\n",
        "guidance_scale = 3 #@param {type:\"integer\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RzLgJyDe7RQL"
      },
      "id": "RzLgJyDe7RQL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8315d73-2735-478b-a185-fabd43e05b4f",
      "metadata": {
        "tags": [],
        "cellView": "form",
        "id": "b8315d73-2735-478b-a185-fabd43e05b4f"
      },
      "outputs": [],
      "source": [
        "#@title Start Generating\n",
        "from diffusers import (LMSDiscreteScheduler, DDPMScheduler, DDIMScheduler, EulerAncestralDiscreteScheduler, EulerDiscreteScheduler, DPMSolverMultistepScheduler, DPMSolverSinglestepScheduler, HeunDiscreteScheduler, PNDMScheduler)\n",
        "import os\n",
        "import datetime\n",
        "from IPython.display import Image, display\n",
        "\n",
        "import random\n",
        "randomlist = random.sample(range(0, 1000000), number_of_seeds)\n",
        "randomlist.sort()\n",
        "\n",
        "\n",
        "x = datetime.datetime.now()\n",
        "sampler_pairs = [('lms', LMSDiscreteScheduler), ('ddpm', DDPMScheduler), ('ddim', DDIMScheduler), ('euler-a', EulerAncestralDiscreteScheduler), ('euler', EulerDiscreteScheduler), ('dpmSM', DPMSolverMultistepScheduler), ('dpmSS', DPMSolverSinglestepScheduler), ('heun', HeunDiscreteScheduler), ('pndm', PNDMScheduler)]\n",
        "sampler_names = [i[0] for i in sampler_pairs]\n",
        "samplers = [i[1] for i in sampler_pairs]\n",
        "sampler_num = sampler_names.index(sampler)\n",
        "scheduler = samplers[sampler_num]\n",
        "\n",
        "W = width\n",
        "H = height\n",
        "\n",
        "for prompt in prompts:\n",
        "    global image;\n",
        "    display_images = False,\n",
        "\n",
        "    output_dir_prompt = f\"generated_images/{x.year}{x.month}{x.day}_{x.hour}{x.minute}{x.second}_{prompt}\"\n",
        "    def out_dir_prompt():\n",
        "        os.makedirs(output_dir_prompt, exist_ok=True)\n",
        "        display_images=False,\n",
        "\n",
        "    def generate_img(directory):\n",
        "        pipeline.scheduler = scheduler.from_config(pipeline.scheduler.config)\n",
        "        generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "        image = pipeline(prompt, num_inference_steps=steps, guidance_scale=scale, generator=generator, width=W, height=H).images[0]\n",
        "        file_name=f\"{directory}/{prompt}_{seed}_{steps}_{scale}_{sampler_names[sampler_num]}_{W}_{H}.png\"\n",
        "        image.save(file_name)\n",
        "        #show image\n",
        "        if display_images:\n",
        "            display(Image(filename=file_name, width=128, height=128))\n",
        "\n",
        "    print(prompt)\n",
        "    #make prompt folder\n",
        "    out_dir_prompt()\n",
        "\n",
        "    #seed selection\n",
        "    seeds=randomlist\n",
        "    steps = sampling_steps\n",
        "    scale = guidance_scale\n",
        "    for seed in seeds:\n",
        "        #image count\n",
        "        print(f\"Seed {seeds.index(seed)+1}/{len(seeds)}\")\n",
        "        print(f\"Seed: {seed}\")\n",
        "        print(f\"Sampler: {sampler_names[sampler_num]}\")\n",
        "        generate_img(output_dir_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start Generating in black and white\n",
        "from diffusers import (LMSDiscreteScheduler, DDPMScheduler, DDIMScheduler, EulerAncestralDiscreteScheduler, EulerDiscreteScheduler, DPMSolverMultistepScheduler, DPMSolverSinglestepScheduler, HeunDiscreteScheduler, PNDMScheduler)\n",
        "import os\n",
        "import datetime\n",
        "from IPython.display import Image, display\n",
        "\n",
        "import random\n",
        "randomlist = random.sample(range(0, 1000000), number_of_seeds)\n",
        "randomlist.sort()\n",
        "\n",
        "\n",
        "x = datetime.datetime.now()\n",
        "sampler_pairs = [('lms', LMSDiscreteScheduler), ('ddpm', DDPMScheduler), ('ddim', DDIMScheduler), ('euler-a', EulerAncestralDiscreteScheduler), ('euler', EulerDiscreteScheduler), ('dpmSM', DPMSolverMultistepScheduler), ('dpmSS', DPMSolverSinglestepScheduler), ('heun', HeunDiscreteScheduler), ('pndm', PNDMScheduler)]\n",
        "sampler_names = [i[0] for i in sampler_pairs]\n",
        "samplers = [i[1] for i in sampler_pairs]\n",
        "sampler_num = sampler_names.index(sampler)\n",
        "scheduler = samplers[sampler_num]\n",
        "\n",
        "W = width\n",
        "H = height\n",
        "\n",
        "for prompt in prompts:\n",
        "    global image;\n",
        "    display_images = False,\n",
        "\n",
        "    def average(color):\n",
        "        return round((color[0] + color[1] + color[2]) // 3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    output_dir_prompt = f\"generated_images_bw/{x.year}{x.month}{x.day}_{x.hour}{x.minute}{x.second}_{prompt}\"\n",
        "    def out_dir_prompt():\n",
        "        os.makedirs(output_dir_prompt, exist_ok=True)\n",
        "        display_images=False,\n",
        "\n",
        "    def generate_img(directory):\n",
        "        pipeline.scheduler = scheduler.from_config(pipeline.scheduler.config)\n",
        "        generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "        image = pipeline(prompt, num_inference_steps=steps, guidance_scale=scale, generator=generator, width=W, height=H).images[0]\n",
        "        blacks = 0\n",
        "        for y in range(image.height):\n",
        "            for x in range(image.width):\n",
        "                gray = average(image.getpixel((x, y)))\n",
        "                if gray > 60:\n",
        "                    image.putpixel((x, y), (255, 255, 255))\n",
        "                else:\n",
        "                    image.putpixel((x, y), (0, 0, 0))\n",
        "                    blacks+=1\n",
        "        print(f\"Black pixels: {blacks}\")\n",
        "        if blacks == 0:\n",
        "          print(\"Image is empty and got skipped\")\n",
        "        else:\n",
        "          file_name=f\"{directory}/{prompt}_{seed}_{steps}_{scale}_{sampler_names[sampler_num]}_{W}_{H}_bw.png\"\n",
        "          image.save(file_name)\n",
        "          #show image\n",
        "          if display_images:\n",
        "            display(Image(filename=file_name, width=128, height=128))\n",
        "\n",
        "    print(prompt)\n",
        "    #make prompt folder\n",
        "    out_dir_prompt()\n",
        "\n",
        "    #seed selection\n",
        "    seeds=randomlist\n",
        "    steps = sampling_steps\n",
        "    scale = guidance_scale\n",
        "    for seed in seeds:\n",
        "        #image count\n",
        "        print(f\"Seed {seeds.index(seed)+1}/{len(seeds)}\")\n",
        "        print(f\"Seed: {seed}\")\n",
        "        print(f\"Sampler: {sampler_names[sampler_num]}\")\n",
        "        generate_img(output_dir_prompt)"
      ],
      "metadata": {
        "id": "gQjr8pUQB4HA"
      },
      "id": "gQjr8pUQB4HA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0810b7b4-732b-43f1-98c9-f4d8151dad13",
      "metadata": {
        "tags": [],
        "cellView": "form",
        "id": "0810b7b4-732b-43f1-98c9-f4d8151dad13"
      },
      "outputs": [],
      "source": [
        "#@title Create Zip File\n",
        "import shutil\n",
        "import os.path\n",
        "\n",
        "directory = '/content/generated_images' #@param {type: \"string\"}\n",
        "\n",
        "# Creating the ZIP file\n",
        "archived = shutil.make_archive(directory, 'zip', directory)\n",
        "\n",
        "if os.path.exists(directory):\n",
        "    print(f\"saved to {archived}\")\n",
        "else:\n",
        "    print(\"ZIP file not created\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "default:Python",
      "language": "python",
      "name": "conda-env-default-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "1b20483d-ecfb-42e4-8349-093c4137d2e6"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}